{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PT_-eL5YN6u2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aYiKRq_NO5M8"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_labels[0])\n",
    "plt.imshow(train_images[0], cmap=\"Greys_r\")\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
    "data = data.shuffle(buffer_size=60000).batch(128).repeat()\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydaUWqbRPeqM"
   },
   "outputs": [],
   "source": [
    "train_steps = 500\n",
    "\n",
    "\n",
    "# example: two (basic) inception blocks\n",
    "# TODO: add 1x1 convs ;)\n",
    "inp = tf.keras.layers.Input((28, 28, 1))\n",
    "\n",
    "\n",
    "conv1_1 = tf.keras.layers.Conv2D(32, 1, activation=tf.nn.relu, padding=\"same\")(inp)\n",
    "conv1_3 = tf.keras.layers.Conv2D(32, 3, activation=tf.nn.relu, padding=\"same\")(inp)\n",
    "conv1_5 = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\")(inp)\n",
    "pool1 = tf.keras.layers.MaxPool2D(3, 1, padding=\"same\")(inp)\n",
    "\n",
    "conc1 = tf.keras.layers.concatenate([conv1_1, conv1_3, conv1_5, pool1])\n",
    "\n",
    "\n",
    "conv2_1 = tf.keras.layers.Conv2D(32, 1, activation=tf.nn.relu, padding=\"same\")(conc1)\n",
    "conv2_3 = tf.keras.layers.Conv2D(32, 3, activation=tf.nn.relu, padding=\"same\")(conc1)\n",
    "conv2_5 = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\")(conc1)\n",
    "pool2 = tf.keras.layers.MaxPool2D(3, 1, padding=\"same\")(conc1)\n",
    "\n",
    "conc2 = tf.keras.layers.concatenate([conv2_1, conv2_3, conv2_5, pool2])\n",
    "\n",
    "flat = tf.keras.layers.Flatten()(conc2)\n",
    "out = tf.keras.layers.Dense(10)(flat)\n",
    "\n",
    "model = tf.keras.Model(inp, out)\n",
    "\n",
    "\n",
    "opt = tf.optimizers.Adam()\n",
    "\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_acc_metric = tf.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sI-63rfoHHXZ"
   },
   "outputs": [],
   "source": [
    "# basic training loops can be done like this\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=[train_acc_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tE970emYHWNj"
   },
   "outputs": [],
   "source": [
    "model.fit(data, steps_per_epoch=1000, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgDgHCyMH4yD"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-3HfTCDL-1t"
   },
   "outputs": [],
   "source": [
    "logits_on_test_set = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqIPQOG1NlYL"
   },
   "outputs": [],
   "source": [
    "train_steps = 500\n",
    "\n",
    "\n",
    "# example: a residual block\n",
    "inp = tf.keras.layers.Input((28, 28, 1))\n",
    "\n",
    "initial_conv = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\")(inp)\n",
    "\n",
    "conv1_1 = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\")(initial_conv)\n",
    "conv1_2 = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\")(conv1_1)\n",
    "\n",
    "out1 = conv1_2 + initial_conv\n",
    "\n",
    "\n",
    "flat = tf.keras.layers.Flatten()(out1)\n",
    "out = tf.keras.layers.Dense(10)(flat)\n",
    "\n",
    "model = tf.keras.Model(inp, out)\n",
    "\n",
    "\n",
    "opt = tf.optimizers.Adam()\n",
    "\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_acc_metric = tf.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj1XXIVc8-2T"
   },
   "outputs": [],
   "source": [
    "# stereotypical train-step-with-function-annotation\n",
    "\n",
    "@tf.function\n",
    "def train_step(imgs, lbls):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(imgs)\n",
    "        xent = loss_fn(lbls, logits)\n",
    "\n",
    "    varis = model.trainable_variables\n",
    "    grads = tape.gradient(xent, varis)\n",
    "    opt.apply_gradients(zip(grads, varis))\n",
    "\n",
    "    return xent, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTvyCwZrQkcw"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for step, (img_batch, lbl_batch) in enumerate(data):\n",
    "    if step > train_steps:\n",
    "        break\n",
    "\n",
    "    xent, logits = train_step(img_batch, lbl_batch)\n",
    "\n",
    "    if not step % 100:\n",
    "        train_acc_metric(lbl_batch, logits)\n",
    "        acc = train_acc_metric.result()\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
    "        train_acc_metric.reset_states()\n",
    "\n",
    "        stop = time.time()\n",
    "        print(\"took {} seconds\\n\".format(stop-start))\n",
    "        start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LkhhvGObTPCD"
   },
   "outputs": [],
   "source": [
    "test_acc_metric = tf.metrics.SparseCategoricalAccuracy()\n",
    "for img_batch, lbl_batch in test_data:\n",
    "    test_acc_metric(lbl_batch, model(img_batch))\n",
    "\n",
    "test_acc_metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3gj5l4_6g2T"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fun_base.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
