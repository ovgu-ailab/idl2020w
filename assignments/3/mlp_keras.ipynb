{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just data stuff\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_labels[0])\n",
    "plt.imshow(train_images[0], cmap=\"Greys_r\")\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images.reshape([-1, 784]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
    "data = data.shuffle(buffer_size=60000).batch(128).repeat()\n",
    "\n",
    "# note: we batch the test data, but do not shuffle/repeat\n",
    "test_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_images.reshape([-1, 784]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 2500\n",
    "\n",
    "n_h = 256\n",
    "layer_list = [tf.keras.layers.Dense(n_h, activation=tf.nn.relu),\n",
    "              tf.keras.layers.Dense(n_h//2, activation=tf.nn.relu),\n",
    "              tf.keras.layers.Dense(10)]  # default is no activation\n",
    "model = tf.keras.Sequential(layer_list)\n",
    "\n",
    "#model.build((None, 784))  # optional -- note None for the batch axis!!\n",
    "\n",
    "opt = tf.optimizers.SGD(0.5)  # tune this\n",
    "# from_logits = True!! #neverforget\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "for step, (img_batch, lbl_batch) in enumerate(data):\n",
    "    if step > train_steps:\n",
    "        break\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(img_batch)\n",
    "        # loss format is generally: first argument targets, second argument outputs\n",
    "        xent = loss_fn(lbl_batch, logits)\n",
    "\n",
    "    # if you didn't build the model, it is important that you get the variables\n",
    "    # AFTER the model has been called the first time\n",
    "    varis = model.trainable_variables\n",
    "    grads = tape.gradient(xent, varis)\n",
    "      \n",
    "    opt.apply_gradients(zip(grads, varis))\n",
    "    \n",
    "    train_acc_metric(lbl_batch, logits)\n",
    "    \n",
    "    if not step % 100:\n",
    "        # this is different from before. there, we only evaluated accuracy\n",
    "        # for one batch. Now, we always average over 100 batches\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, train_acc_metric.result()))\n",
    "        train_acc_metric.reset_states()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is very convenient -- before, we usually had code that\n",
    "# evaluates the whole test set at once -- this won't work for\n",
    "# large datasets/models. With metrics, we can just iterate\n",
    "# over the data and the metric takes care of averaging etc.\n",
    "\n",
    "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "for img_batch, lbl_batch in test_data:\n",
    "    test_acc_metric(lbl_batch, model(img_batch))\n",
    "print(\"Test acc: {}\".format(test_acc_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
