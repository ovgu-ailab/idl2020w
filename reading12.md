---
layout: default
title: Reading Assignment
id: reading12
---


# Reading Assignment: Introspection - Part II

## Main Reading

1. [Sanity checks for Saliency Maps](https://arxiv.org/abs/1810.03292) - a reminder that explanations can be misleading

2. [When Explanations Lie: Why Many Modified BP Attributions Fail](https://arxiv.org/abs/1912.09818), [ICML slides](https://icml.cc/media/Slides/icml/2020/virtual(no-parent)-14-18-00UTC-5929-when_explanatio.pdf)

## Selective Reading (i.e. pick one!)

As additional (mandatory) reading assignment, here are 5 papers that propose different advanced introspection techniques. They are all worth reading, but you just need to read one of them.

Please use the poll provided on Mattermost to choose your paper by voting!
Pick the one you are most interested in unless it already has 7 votes. In that case, consider reading a less popular one because we are aiming for a balanced distribution. Of course, you can also read more than one paper.

You should be prepared to explain the most important / innovative aspects of the paper to others.

1. [PatternNet & PatternAttribution ](https://arxiv.org/abs/1705.05598)

2. [Testing with Concept Activation Vectors](https://towardsdatascience.com/tcav-interpretability-beyond-feature-attribution-79b4d3610b4d)

3. [Information Bottlenecks for Attribution](https://openreview.net/forum?id=S1xWh1rYwB)

4. [DeepLIFT - Learning Important Features Through Propagating Activation Differences](https://arxiv.org/abs/1704.02685) (paper including links to talks and slides)

5. [GradNAPs - Gradient-Adjusted Neuron Activation Profiles for Comprehensive Introspection of Convolutional Speech Recognition Models](https://arxiv.org/abs/2002.08125)
